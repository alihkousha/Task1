{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kBG-Icr8Oda_"
   },
   "source": [
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "ZCG9T_8DOggR"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('https://query.data.world/s/k77dz3twrne5hs62f2fgn7rj6lrpwg')\n",
    "users = pd.DataFrame({'user':df.manufacturer.unique()})\n",
    "users = np.array(list(users))\n",
    "pro = pd.DataFrame({'product':df.product_name.unique()})\n",
    "pro = np.array(list(pro))\n",
    "# users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "Sc_a_dXn-s7d"
   },
   "outputs": [],
   "source": [
    "users = pd.DataFrame({'user':df.manufacturer.unique()})\n",
    "users_train = users.iloc[:, :663]\n",
    "users_test = users.iloc[:, 663:]\n",
    "users_train = np.array(list(users_train))\n",
    "users_test = np.array(list(users_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "ajrkmxV62560"
   },
   "outputs": [],
   "source": [
    "pro = pd.DataFrame({'product':df.product_name.unique()})\n",
    "pro_train = pro.iloc[:, :2491]\n",
    "pro_test = pro.iloc[:, 2491:]\n",
    "pro_train = np.array(list(pro_train))\n",
    "pro_test = np.array(list(pro_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "ppqBiKvDyJTl"
   },
   "outputs": [],
   "source": [
    "pro_met = tf.data.Dataset.from_tensor_slices((np.array(list(df['manufacturer']))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rQmGV4zbTmCK"
   },
   "source": [
    "#recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0R4wx7LtxQcz",
    "outputId": "3561f007-5127-4c96-8e1b-3c52ba0fd387"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l\r\u001b[K     |███▉                            | 10 kB 25.8 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 20 kB 28.6 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 30 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 40 kB 36.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 51 kB 40.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 61 kB 32.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 71 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 81 kB 27.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 85 kB 3.5 MB/s \n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q tensorflow-recommenders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "hjp4eAZHO9LH"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "import tempfile\n",
    "\n",
    "from typing import Dict, Text\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "DBU9dPEhwrdC"
   },
   "outputs": [],
   "source": [
    "embedding_dimension = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "9v4s-8GXxmJs"
   },
   "outputs": [],
   "source": [
    "user_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.StringLookup(\n",
    "      vocabulary=users, mask_token=None),\n",
    "  # We add an additional embedding to account for unknown tokens.\n",
    "  tf.keras.layers.Embedding(len(users) + 1, embedding_dimension)\n",
    "])\n",
    "\n",
    "\n",
    "pro_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.StringLookup(\n",
    "      vocabulary=pro, mask_token=None),\n",
    "  tf.keras.layers.Embedding(len(pro) + 1, embedding_dimension)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "eIThpubkx_sT"
   },
   "outputs": [],
   "source": [
    "metrics = tfrs.metrics.FactorizedTopK(\n",
    "  candidates=pro_met.batch(128).map(pro_model)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "dmz9_dUNzs_j"
   },
   "outputs": [],
   "source": [
    "task = tfrs.tasks.Retrieval(\n",
    "  metrics=metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "6gUsQvN23RCG"
   },
   "outputs": [],
   "source": [
    "class firstModel(tfrs.Model):\n",
    "    def __init__(self, user_model, pro_model):\n",
    "        super().__init__()\n",
    "        self.pro_model: tf.keras.Model = pro_model\n",
    "        self.user_model: tf.keras.Model = user_model\n",
    "        self.task: tf.keras.layers.Layer = task\n",
    "    def compute_loss(self, features: Dict[Text, tf.Tensor], training = False):\n",
    "        user_embeddings = self.user_model(features[0])\n",
    "        pro_embeddings = self.pro_model(features[0])\n",
    "\n",
    "        return self.task(user_embeddings, pro_embeddings)\n",
    "# Dict[Text, tf.Tensor]\n",
    "# pro_model\n",
    "# user_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "toerJ5lG6Ate"
   },
   "outputs": [],
   "source": [
    "model = firstModel(user_model, pro_model)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DOg1S8a_7RUU",
    "outputId": "570183c2-4db6-4589-8ecb-d08973ba7f96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1/1 [==============================] - 0s 98ms/step - factorized_top_k/top_1_categorical_accuracy: 1.0000 - factorized_top_k/top_5_categorical_accuracy: 1.0000 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 0.0000e+00 - regularization_loss: 0.0000e+00 - total_loss: 0.0000e+00\n",
      "Epoch 2/3\n",
      "1/1 [==============================] - 0s 82ms/step - factorized_top_k/top_1_categorical_accuracy: 1.0000 - factorized_top_k/top_5_categorical_accuracy: 1.0000 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 0.0000e+00 - regularization_loss: 0.0000e+00 - total_loss: 0.0000e+00\n",
      "Epoch 3/3\n",
      "1/1 [==============================] - 0s 95ms/step - factorized_top_k/top_1_categorical_accuracy: 1.0000 - factorized_top_k/top_5_categorical_accuracy: 1.0000 - factorized_top_k/top_10_categorical_accuracy: 1.0000 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 0.0000e+00 - regularization_loss: 0.0000e+00 - total_loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0912470850>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(users_train, pro_train, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "yd0de_ew91So"
   },
   "outputs": [],
   "source": [
    "# model.evaluate(users_test, pro_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mbhc9FzuIAuY",
    "outputId": "a87bacd9-43ce-45f1-dd36-ba35f91fde7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for user 42: [b'Hornby' b'FunkyBuys' b'ccf']\n"
     ]
    }
   ],
   "source": [
    "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
    "index.index_from_dataset(\n",
    "  tf.data.Dataset.zip((pro_met.batch(100), pro_met.batch(100).map(model.pro_model)))\n",
    ")\n",
    "_, titles = index(tf.constant([\"42\"]))\n",
    "print(f\"Recommendations for user 42: {titles[0, :3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MoLnq2qfMl1L",
    "outputId": "9027b10f-6412-4777-a3e6-dd5e2e3cdd8c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as query_with_exclusions while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp2rlpgyvd/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp2rlpgyvd/model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations: [b'Hornby' b'FunkyBuys' b'ccf']\n"
     ]
    }
   ],
   "source": [
    "# Export the query model.\n",
    "with tempfile.TemporaryDirectory() as tmp:\n",
    "  path = os.path.join(tmp, \"model\")\n",
    "\n",
    "  # Save the index.\n",
    "  tf.saved_model.save(index, path)\n",
    "\n",
    "  # Load it back; can also be done in TensorFlow Serving.\n",
    "  loaded = tf.saved_model.load(path)\n",
    "\n",
    "  # Pass a user id in, get top predicted movie titles back.\n",
    "  scores, titles = loaded([\"42\"])\n",
    "\n",
    "  print(f\"Recommendations: {titles[0][:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m97WbxRrM_Gp"
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "TFRS_task1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
